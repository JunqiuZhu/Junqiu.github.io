

<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<title>Junqiu Zhu: Research Page</title>
<link href="style.css" rel="stylesheet" type="text/css">
</head>

<body style="width: 70%; margin: 0 auto">

<table class="inset" cellspacing="10pt">
  <tr>
    <td><img src="zjq.jpg" height="205" width="200"></td>
    <td class="inset">
      <h1>Junqiu Zhu（朱君秋）</h1>
      <h3>zhujunqiu at mail dot sdu dot edu dot cn</h3>
	
I am a Ph.D. candidate at Shandong University, China working under the supervision of  Prof. <a href="http://vr.sdu.edu.cn/info/1010/1073.htm">Xiangxu Meng</a>,
co-surpervised by Prof. <a href="http://vr.sdu.edu.cn/info/1010/1060.htm">Lu Wang</a>, Prof. <a href="http://vr.sdu.edu.cn/info/1010/1062.htm">Yanning Xu</a> and Prof.
<a href="https://sites.cs.ucsb.edu/~lingqi/">Lingqi Yan</a>. My research is in Computer Graphics.<br>NEWS! I am honored to receive the <a href="http://games-cn.org/2021-4/">2021 Style3D Graphics Scholarship</a></br>


    </td>
  </tr>

	

 
  <tr>
  <td colspan="2">

    <h2>Selected Publications</h2>
    <table>
	<tr>
        <td valign="top"><img src="realtimeglint.jpg" height="192" width="256"></td>
        <td>
      <b>Real-Time Microstructure Rendering with MIP-mapped Normal Map Samples</b><br>
      Haowen Yan, Junqiu Zhu (dual first author), Xiangxu Meng, Yanning Xu, Lu Wang, Ling-Qi Yan<br>
       <i>Computer Graphics Forum (minor revisions)</i>
     [PDF](Coming Soon) <br>
     

    Normal map-based microstructure rendering method can generate both glint and scratch appearance accurately, but the extra high-resolution normal map 
		that defines every microfacet normal may incur high storage and computation costs. We present an example-based real-time rendering method 
		for arbitrary microstructure materials, which also greatly reduces required storage space. Our method takes a small-size normal map sample 
		as input. We implicitly synthesize a high-resolution normal map from the normal map sample and construct MIP-mapped position-normal 4D Gaussian 
		lobes. Based on the above MIP-mapped 4D lobes and a LUT data structure for the synthesized high-resolution normal map, an efficient Gaussian query 
		method is presented to evaluate the P-NDFs (Position-Normal Distribution Functions) for shading. We can render complex scenes with both glint and 
		scratch surfaces in real-time ( &gt 30 fps) with a full high-definition resolution, and the space required for each microstructure material is decreased to 30MB. <br><br>

        </td>
      </tr>
 <tr>
        <td valign="top"><img src="comlum.jpg" height="152" width="256"></td>
        <td>
      <b>Neural Complex Luminaires: Representation and Rendering</b><br>
     Junqiu Zhu*, Yaoyi Bai*, Zilin Xu* (equal contribution), Steve Bako, Edgar Velázquez-Armendáriz, Lu Wang, Pradeep Sen, Miloš Hašan, Ling-Qi Yan<br>
      <i>ACM Transactions on Graphics (Proceedings of SIGGRAPH 2021)</i>
      <a href="https://sites.cs.ucsb.edu/~lingqi/publications/paper_complum.pdf">[PDF]</a>
      <a href="https://sites.cs.ucsb.edu/~lingqi/publications/video_complum.mp4">[Video]</a>
      [Code](Coming soon!)<br>
     

    Physically-based rendering of complex luminaires, such as grand chandeliers in concert halls, 
		can be extremely costly. The emitting sources are typically encased in complex
		refractive geometry, creating difficult light paths that require many samples to 
		evaluate with Monte Carlo approaches. Previous work has attempted to speed up this process,
		but the methods are either inaccurate, require very large lightfield storage, and/or do not fit 
		well into modern path tracing frameworks. Inspired by the success of deep networks, 
		which can model complex relationships robustly and be evaluated efficiently, 
		we propose to use a machine learning framework to compress a complex luminaire's light field into an implicit neural
		representation. Our approach can easily plug into conventional renderers, as it works with the standard techniques of 
		path tracing and multiple importance sampling (MIS). Our solution is to train three networks to perform the essential operations 
		for evaluating the complex luminaire at a specific point and view direction, importance sampling a point on the luminaire given 
		a shading location, and blending to determine the transparency of luminaire queries to properly combine them with other scene elements. 
		We perform favorably relative to state-of-the-art approaches and render final images that are close to the high sample count reference with 
		only a fraction of the computation and storage costs, with no need to store the original luminaire geometry and materials.<br><br>

        </td>
  </tr>
     
      <tr>
        <td valign="top"><img src="svbrdf.jpg" height="192" width="256"></td>
        <td>
      <b>A Stationary SVBRDF Material Modeling Method Based on Discrete Microsurface</b><br>
      Junqiu Zhu, Yanning Xu, Lu Wang<br>
      <i>Computer Graphics Forum (Pacific Graphics 2019)</i>
      <a href="https://onlinelibrary.wiley.com/doi/10.1111/cgf.13876">[PDF]</a><br>
     

     Microfacet theory is commonly used to build reflectance models for surfaces.
		While traditional microfacet‐based models assume that the distribution of a surface's microstructure is continuous, 
		recent studies indicate that some surfaces with tiny, discrete and stochastic facets exhibit glittering visual effects, 
		while some surfaces with structured features exhibit anisotropic specular reflection. Accordingly, this paper proposes an efficient
		and stationary method of surface material modeling to process both glittery and non‐glittery surfaces in a consistent way. Our method 
		comprises two steps: in the preprocessing step, we take a fixed‐size sample normal map as input, then organize 4D microfacet trees in position and 
		normal space for arbitrary‐sized surfaces; we also cluster microfacets into 4D K‐lobes via the adaptive k‐means method. In the rendering step, 
		moreover, surface normals can be efficiently evaluated using pre‐clustered microfacets. Our method is able to efficiently render any structured, 
		discrete and continuous micro‐surfaces using a precisely reconstructed surface NDF.
		Our method is both faster and uses less memory compared to the state‐of‐the‐art glittery surface modeling works.<br><br>

        </td>
      </tr>

   <tr>
 

     
    



</table>
</body>

</html>

